import cv2
import numpy as np
import os
import json
import time
from PySide6.QtWidgets import (
    QDialog, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, 
    QComboBox, QSpinBox, QDoubleSpinBox, QGroupBox, QGridLayout,
    QMessageBox, QTabWidget, QWidget, QTextEdit, QCheckBox
)
from PySide6.QtCore import Qt, Signal, QThread, QMutex, QTimer
from PySide6.QtGui import QImage, QPixmap, QFont
from ultralytics import YOLO
import math

class DistanceCalculationThread(QThread):
    frame_signal = Signal(object, object, dict)  # –ö–∞–¥—Ä, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    error_signal = Signal(str)
    
    def __init__(self, camera1_url, camera2_url, model_path, baseline, calibration_data=None, sync_data=None):
        super().__init__()
        self.camera1_url = camera1_url
        self.camera2_url = camera2_url
        self.model_path = model_path
        self.baseline = baseline  # –≤ —Å–∞–Ω—Ç–∏–º–µ—Ç—Ä–∞—Ö
        self.calibration_data = calibration_data
        self.sync_data = sync_data
        self.running = False
        self.lock = QMutex()
        self.detected_objects = {}
        
    def run(self):
        self.running = True
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º YOLO –º–æ–¥–µ–ª—å
        try:
            model = YOLO(self.model_path)
        except Exception as e:
            self.error_signal.emit(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.running = False
            return
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∏
        cap1 = cv2.VideoCapture(self.camera1_url)
        cap2 = cv2.VideoCapture(self.camera2_url)
        
        if not cap1.isOpened() or not cap2.isOpened():
            self.error_signal.emit("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –æ–¥–Ω—É –∏–ª–∏ –æ–±–µ –∫–∞–º–µ—Ä—ã")
            self.running = False
            return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Ç—Ä–∏—Ü—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        camera_matrix1 = None
        camera_matrix2 = None
        dist_coeffs1 = None
        dist_coeffs2 = None
        
        if self.calibration_data:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            if 'camera1' in self.calibration_data and 'camera2' in self.calibration_data:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å camera1 –∏ camera2
                try:
                    camera_matrix1 = np.array(self.calibration_data['camera1']['matrix'])
                    dist_coeffs1 = np.array(self.calibration_data['camera1']['distortion'])
                    
                    camera_matrix2 = np.array(self.calibration_data['camera2']['matrix'])
                    dist_coeffs2 = np.array(self.calibration_data['camera2']['distortion'])
                except (KeyError, TypeError) as e:
                    print(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–æ URL
            elif self.camera1_url in self.calibration_data and self.camera2_url in self.calibration_data:
                camera_matrix1 = np.array(self.calibration_data[self.camera1_url]['camera_matrix'])
                dist_coeffs1 = np.array(self.calibration_data[self.camera1_url]['dist_coeffs'])
                
                camera_matrix2 = np.array(self.calibration_data[self.camera2_url]['camera_matrix'])
                dist_coeffs2 = np.array(self.calibration_data[self.camera2_url]['dist_coeffs'])
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            else:
                print("–î–∞–Ω–Ω—ã–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–º–µ—é—Ç—Å—è, –Ω–æ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É")
        
        drift_rate = 0
        if self.sync_data:
            drift_rate = self.sync_data.get('drift_rate', 0)
        
        frame_count = 0
        start_time = time.time()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
        while self.running:
            # –ó–∞—Ö–≤–∞—Ç –∫–∞–¥—Ä–æ–≤
            ret1, frame1 = cap1.read()
            if not ret1:
                continue
                
            # –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∫–∞–º–µ—Ä
            frames_to_skip = int(drift_rate * (time.time() - start_time))
            if frames_to_skip > 0:
                for _ in range(frames_to_skip):
                    cap2.read()  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä—ã –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            
            ret2, frame2 = cap2.read()
            if not ret2:
                continue
            
            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –∏—Å–∫–∞–∂–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            if camera_matrix1 is not None and dist_coeffs1 is not None:
                try:
                    h, w = frame1.shape[:2]
                    newcameramtx1, roi1 = cv2.getOptimalNewCameraMatrix(camera_matrix1, dist_coeffs1, (w,h), 0, (w,h))
                    frame1 = cv2.undistort(frame1, camera_matrix1, dist_coeffs1, None, newcameramtx1)
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π –∫–∞–º–µ—Ä—ã 1: {e}")
                
            if camera_matrix2 is not None and dist_coeffs2 is not None:
                try:
                    h, w = frame2.shape[:2]
                    newcameramtx2, roi2 = cv2.getOptimalNewCameraMatrix(camera_matrix2, dist_coeffs2, (w,h), 0, (w,h))
                    frame2 = cv2.undistort(frame2, camera_matrix2, dist_coeffs2, None, newcameramtx2)
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π –∫–∞–º–µ—Ä—ã 2: {e}")
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –æ–±–æ–∏—Ö –∫–∞–¥—Ä–∞—Ö
            results1 = model(frame1)
            results2 = model(frame2)
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            display_frame1 = frame1.copy()
            display_frame2 = frame2.copy()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –Ω–∞ –∫–∞–¥—Ä—ã, —á—Ç–æ–±—ã –∏—Ö –º–æ–∂–Ω–æ –±—ã–ª–æ –æ—Ç–ª–∏—á–∏—Ç—å
            cv2.putText(display_frame1, "CAM 1", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
            cv2.putText(display_frame2, "CAM 2", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            detections = {}
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∫–∞–∂–¥–æ–π –∫–∞–º–µ—Ä–µ
            objects_cam1 = {}
            objects_cam2 = {}
            
            # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
            all_detected_objects = []
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–∫—Ç—ã —Å –ø–µ—Ä–≤–æ–π –∫–∞–º–µ—Ä—ã
            if len(results1) > 0:
                boxes1 = results1[0].boxes
                for i, box in enumerate(boxes1):
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                    conf = float(box.conf)
                    cls_id = int(box.cls)
                    cls_name = model.names[cls_id]
                    
                    center_x1 = (x1 + x2) // 2
                    center_y1 = (y1 + y2) // 2
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                    all_detected_objects.append({
                        'camera': 1,
                        'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                        'center_x': center_x1, 'center_y': center_y1,
                        'cls_id': cls_id, 'cls_name': cls_name, 'conf': conf,
                        'box_index': i
                    })
                    
                    # –í—Ä–µ–º–µ–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–∞
                    obj_id = f"{cls_name}_{i}"
                    objects_cam1[obj_id] = {
                        'bbox': (x1, y1, x2, y2),
                        'center': (center_x1, center_y1),
                        'class': cls_name,
                        'class_id': cls_id,
                        'confidence': conf
                    }
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–∫—Ç—ã —Å–æ –≤—Ç–æ—Ä–æ–π –∫–∞–º–µ—Ä—ã
            if len(results2) > 0:
                boxes2 = results2[0].boxes
                for i, box in enumerate(boxes2):
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                    conf = float(box.conf)
                    cls_id = int(box.cls)
                    cls_name = model.names[cls_id]
                    
                    center_x2 = (x1 + x2) // 2
                    center_y2 = (y1 + y2) // 2
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–∏—Å–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                    all_detected_objects.append({
                        'camera': 2,
                        'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                        'center_x': center_x2, 'center_y': center_y2,
                        'cls_id': cls_id, 'cls_name': cls_name, 'conf': conf,
                        'box_index': i
                    })
                    
                    # –í—Ä–µ–º–µ–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—ä–µ–∫—Ç–∞
                    obj_id = f"{cls_name}_{i}"
                    objects_cam2[obj_id] = {
                        'bbox': (x1, y1, x2, y2),
                        'center': (center_x2, center_y2),
                        'class': cls_name,
                        'class_id': cls_id,
                        'confidence': conf
                    }
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏ –∏ –≤—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            matched_pairs = []
            
            for obj1 in [obj for obj in all_detected_objects if obj['camera'] == 1]:
                best_match = None
                min_distance = float('inf')
                
                for obj2 in [obj for obj in all_detected_objects if obj['camera'] == 2]:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–æ—Ç –∂–µ –∫–ª–∞—Å—Å –æ–±—ä–µ–∫—Ç–∞
                    if obj1['cls_id'] == obj2['cls_id']:
                        # –î–∏—Å–ø–∞—Ä–∏—Ç–µ—Ç - —ç—Ç–æ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ x-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö —Ü–µ–Ω—Ç—Ä–∞ –æ–±—ä–µ–∫—Ç–∞
                        disparity = abs(obj1['center_x'] - obj2['center_x'])
                        
                        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ —Ñ–æ—Ä–º—É–ª–µ: distance = (baseline * focal_length) / disparity
                        if disparity > 0:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–ª–∏ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                            focal_length = 800  # –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                            if camera_matrix1 is not None:
                                focal_length = camera_matrix1[0, 0]
                                
                            # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Å–∞–Ω—Ç–∏–º–µ—Ç—Ä–∞—Ö
                            distance = (self.baseline * focal_length) / disparity
                            
                            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
                            if distance < min_distance:
                                min_distance = distance
                                best_match = obj2
                                best_match['distance'] = distance
                
                # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä—É –∏ —Ä–∏—Å—É–µ–º –Ω–∞ –æ–±–æ–∏—Ö –∫–∞–¥—Ä–∞—Ö
                if best_match:
                    matched_pairs.append((obj1, best_match))
                    
                    distance = best_match['distance']
                    
                    # –¶–≤–µ—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                    if distance < 200:  # –±–ª–∏–∂–µ 2 –º–µ—Ç—Ä–æ–≤
                        color = (0, 0, 255)  # –∫—Ä–∞—Å–Ω—ã–π –¥–ª—è –±–ª–∏–∑–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                    elif distance < 500:  # 2-5 –º–µ—Ç—Ä–æ–≤
                        color = (0, 255, 255)  # –∂–µ–ª—Ç—ã–π –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                    else:
                        color = (0, 255, 0)  # –∑–µ–ª–µ–Ω—ã–π –¥–ª—è –¥–∞–ª–µ–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                    
                    # –†–∏—Å—É–µ–º –Ω–∞ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ
                    cv2.rectangle(display_frame1, 
                                 (obj1['x1'], obj1['y1']), 
                                 (obj1['x2'], obj1['y2']), 
                                 color, 2)
                    
                    # –¢–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –Ω–∞ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ
                    label1 = f"{obj1['cls_name']} {distance/100:.2f}m"
                    cv2.putText(display_frame1, label1, 
                               (obj1['x1'], obj1['y1'] - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                    
                    # –†–∏—Å—É–µ–º –Ω–∞ –≤—Ç–æ—Ä–æ–º –∫–∞–¥—Ä–µ
                    cv2.rectangle(display_frame2, 
                                 (best_match['x1'], best_match['y1']), 
                                 (best_match['x2'], best_match['y2']), 
                                 color, 2)
                    
                    # –¢–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –Ω–∞ –≤—Ç–æ—Ä–æ–º –∫–∞–¥—Ä–µ
                    label2 = f"{best_match['cls_name']} {distance/100:.2f}m"
                    cv2.putText(display_frame2, label2, 
                               (best_match['x1'], best_match['y1'] - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π –¥–ª—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
                    obj_id = f"{obj1['cls_name']}_{obj1['box_index']}"
                    detections[obj_id] = {
                        'class': obj1['cls_name'],
                        'distance': distance/100,  # –≤ –º–µ—Ç—Ä–∞—Ö
                        'position_cam1': (obj1['center_x'], obj1['center_y']),
                        'position_cam2': (best_match['center_x'], best_match['center_y']),
                        'bbox_cam1': (obj1['x1'], obj1['y1'], obj1['x2'], obj1['y2']),
                        'bbox_cam2': (best_match['x1'], best_match['y1'], best_match['x2'], best_match['y2']),
                        'confidence': obj1['conf'] * best_match['conf']  # –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                    }
            
            # –†–∏—Å—É–µ–º –Ω–µ–ø–∞—Ä–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –ø–µ—Ä–≤–æ–π –∫–∞–º–µ—Ä–µ
            for obj_id, obj_data in objects_cam1.items():
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ –ø–∞—Ä–∞—Ö
                if any(matched_obj1['box_index'] == int(obj_id.split('_')[1]) and 
                       matched_obj1['cls_name'] == obj_data['class'] 
                       for matched_obj1, _ in matched_pairs):
                    continue
                
                # –†–∏—Å—É–µ–º –æ–±—ä–µ–∫—Ç –±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏
                x1, y1, x2, y2 = obj_data['bbox']
                cls_name = obj_data['class']
                
                # –°–µ—Ä—ã–π —Ü–≤–µ—Ç –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –±–µ–∑ –ø–∞—Ä—ã
                color = (128, 128, 128)
                
                cv2.rectangle(display_frame1, (x1, y1), (x2, y2), color, 2)
                label = f"{cls_name} (no match)"
                cv2.putText(display_frame1, label, (x1, y1 - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # –†–∏—Å—É–µ–º –Ω–µ–ø–∞—Ä–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –≤—Ç–æ—Ä–æ–π –∫–∞–º–µ—Ä–µ
            for obj_id, obj_data in objects_cam2.items():
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ –ø–∞—Ä–∞—Ö
                if any(matched_obj2['box_index'] == int(obj_id.split('_')[1]) and 
                       matched_obj2['cls_name'] == obj_data['class'] 
                       for _, matched_obj2 in matched_pairs):
                    continue
                
                # –†–∏—Å—É–µ–º –æ–±—ä–µ–∫—Ç –±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏
                x1, y1, x2, y2 = obj_data['bbox']
                cls_name = obj_data['class']
                
                # –°–µ—Ä—ã–π —Ü–≤–µ—Ç –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –±–µ–∑ –ø–∞—Ä—ã
                color = (128, 128, 128)
                
                cv2.rectangle(display_frame2, (x1, y1), (x2, y2), color, 2)
                label = f"{cls_name} (no match)"
                cv2.putText(display_frame2, label, (x1, y1 - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–¥—Ä–µ
            frame_info = {
                'frame_count': frame_count,
                'timestamp': time.time() - start_time,
                'num_detections': len(detections),
                'detections': detections
            }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ - –æ–±–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–∞
            self.frame_signal.emit(display_frame1, display_frame2, frame_info)
            
            frame_count += 1
            
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        cap1.release()
        cap2.release()
        
    def stop(self):
        self.running = False
        self.wait()

class DistanceCalculatorDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("–ò–∑–º–µ—Ä–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")
        self.setMinimumSize(1200, 800)
        
        self.calibration_data = {}
        self.sync_data = {}
        self.calculation_thread = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.is_calibrated = False
        self.is_synced = False
        self.load_calibration_data()
        self.load_sync_data()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π layout
        main_layout = QVBoxLayout()
        
        # –í–µ—Ä—Ö–Ω—è—è –ø–∞–Ω–µ–ª—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–∞—Ç—É—Å–µ
        status_layout = QHBoxLayout()
        
        self.calibration_status_label = QLabel(f"–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞: {'‚úÖ' if self.is_calibrated else '‚ùå'}")
        self.sync_status_label = QLabel(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: {'‚úÖ' if self.is_synced else '‚ùå'}")
        
        status_layout.addWidget(self.calibration_status_label)
        status_layout.addWidget(self.sync_status_label)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if not self.is_calibrated:
            calibrate_btn = QPushButton("–í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–∞–ª–∏–±—Ä–æ–≤–∫—É")
            calibrate_btn.clicked.connect(self.on_calibrate_clicked)
            status_layout.addWidget(calibrate_btn)
            
        if not self.is_synced:
            sync_btn = QPushButton("–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é")
            sync_btn.clicked.connect(self.on_sync_clicked)
            status_layout.addWidget(sync_btn)
        
        main_layout.addLayout(status_layout)
        
        # –ü–∞–Ω–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–∫
        settings_group = QGroupBox("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")
        settings_layout = QGridLayout()
        
        # –í—ã–±–æ—Ä –∫–∞–º–µ—Ä
        settings_layout.addWidget(QLabel("–ö–∞–º–µ—Ä–∞ 1:"), 0, 0)
        self.cam1_combo = QComboBox()
        settings_layout.addWidget(self.cam1_combo, 0, 1)
        
        settings_layout.addWidget(QLabel("–ö–∞–º–µ—Ä–∞ 2:"), 1, 0)
        self.cam2_combo = QComboBox()
        settings_layout.addWidget(self.cam2_combo, 1, 1)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞–º–µ—Ä –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ
        self.load_cameras()
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ YOLO
        settings_layout.addWidget(QLabel("–ú–æ–¥–µ–ª—å YOLO:"), 0, 2)
        self.model_combo = QComboBox()
        self.load_models()
        settings_layout.addWidget(self.model_combo, 0, 3)
        
        # –ë–∞–∑–∏—Å (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–∞–º–µ—Ä–∞–º–∏)
        settings_layout.addWidget(QLabel("–ë–∞–∑–∏—Å (—Å–º):"), 1, 2)
        self.baseline_spin = QDoubleSpinBox()
        self.baseline_spin.setRange(1, 1000)
        self.baseline_spin.setValue(10.0)
        self.baseline_spin.setDecimals(1)
        settings_layout.addWidget(self.baseline_spin, 1, 3)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–∏—Å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫, –µ—Å–ª–∏ –µ—Å—Ç—å
        if self.parent() and hasattr(self.parent(), 'config'):
            distance_settings = self.parent().config.get_distance_measure_settings()
            if 'baseline' in distance_settings:
                self.baseline_spin.setValue(distance_settings['baseline'])
        
        # –†–µ–∂–∏–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        settings_layout.addWidget(QLabel("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –¥–ª—è –∫–∞–º–µ—Ä—ã:"), 0, 4)
        self.display_combo = QComboBox()
        self.display_combo.addItem("–ö–∞–º–µ—Ä–∞ 1")
        self.display_combo.addItem("–ö–∞–º–µ—Ä–∞ 2")
        settings_layout.addWidget(self.display_combo, 0, 5)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        self.show_distances_check = QCheckBox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")
        self.show_distances_check.setChecked(True)
        settings_layout.addWidget(self.show_distances_check, 1, 4, 1, 2)
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        self.start_btn = QPushButton("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ")
        self.start_btn.clicked.connect(self.start_distance_calculation)
        settings_layout.addWidget(self.start_btn, 0, 6, 2, 1)
        
        self.stop_btn = QPushButton("–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å")
        self.stop_btn.clicked.connect(self.stop_distance_calculation)
        self.stop_btn.setEnabled(False)
        settings_layout.addWidget(self.stop_btn, 0, 7, 2, 1)
        
        settings_group.setLayout(settings_layout)
        main_layout.addWidget(settings_group)
        
        # –û–±–ª–∞—Å—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        display_layout = QHBoxLayout()
        
        # –í–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setMinimumSize(800, 600)
        self.video_label.setText("–ù–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ' –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        display_layout.addWidget(self.video_label, 7)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–µ—Ç–µ–∫—Ü–∏–∏
        info_layout = QVBoxLayout()
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö
        objects_group = QGroupBox("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã")
        objects_layout = QVBoxLayout()
        self.objects_text = QTextEdit()
        self.objects_text.setReadOnly(True)
        objects_layout.addWidget(self.objects_text)
        objects_group.setLayout(objects_layout)
        info_layout.addWidget(objects_group)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats_group = QGroupBox("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        stats_layout = QVBoxLayout()
        self.stats_text = QTextEdit()
        self.stats_text.setReadOnly(True)
        stats_layout.addWidget(self.stats_text)
        stats_group.setLayout(stats_layout)
        info_layout.addWidget(stats_group)
        
        display_layout.addLayout(info_layout, 3)
        
        main_layout.addLayout(display_layout)
        
        self.setLayout(main_layout)
        
        # –ë–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É —Å—Ç–∞—Ä—Ç–∞, –µ—Å–ª–∏ –Ω–µ—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–ª–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        self.start_btn.setEnabled(self.is_calibrated and self.is_synced)
        if not self.start_btn.isEnabled():
            warning = "‚ö†Ô∏è –î–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –∫–∞–º–µ—Ä"
            self.stats_text.append(warning)
        
        # –¢–∞–π–º–µ—Ä –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.update_timer = QTimer()
        self.update_timer.timeout.connect(self.update_statistics)
        self.update_timer.start(1000)  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
        
    def load_cameras(self):
        try:
            with open("cameras.txt", "r") as f:
                camera_lines = [line.strip() for line in f if line.strip()]
                
            self.cam1_combo.clear()
            self.cam2_combo.clear()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ –∏–∑ cameras.txt
            cameras = []
            camera_names = []
            
            for line in camera_lines:
                parts = line.strip().split(' ', 1)  # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∏–º—è –∏ URL
                if len(parts) == 2:
                    camera_name = parts[0]
                    camera_url = parts[1]
                    cameras.append(camera_url)
                    camera_names.append(camera_name)
                else:
                    # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ URL
                    cameras.append(line)
                    camera_names.append(f"–ö–∞–º–µ—Ä–∞ {len(cameras)}")
            
            for i, (camera_url, camera_name) in enumerate(zip(cameras, camera_names)):
                self.cam1_combo.addItem(f"{camera_name}", camera_url)
                self.cam2_combo.addItem(f"{camera_name}", camera_url)
                
            if len(cameras) > 1:
                self.cam2_combo.setCurrentIndex(1)
                    
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–∞–Ω–µ–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–∞–º–µ—Ä—ã –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Ö
            if self.parent() and hasattr(self.parent(), 'config'):
                distance_settings = self.parent().config.get_distance_measure_settings()
                if 'cameras' in distance_settings and len(distance_settings['cameras']) >= 2:
                    cam1 = distance_settings['cameras'][0]
                    cam2 = distance_settings['cameras'][1]
                    
                    # –ù–∞—Ö–æ–¥–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∫–∞–º–µ—Ä—ã –ø–æ URL –≤ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–±–æ–±–æ–∫—Å–æ–≤
                    for i in range(self.cam1_combo.count()):
                        if self.cam1_combo.itemData(i) == cam1:
                            self.cam1_combo.setCurrentIndex(i)
                            break
                            
                    for i in range(self.cam2_combo.count()):
                        if self.cam2_combo.itemData(i) == cam2:
                            self.cam2_combo.setCurrentIndex(i)
                            break
                        
        except Exception as e:
            QMessageBox.critical(self, "–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ cameras.txt: {e}")
            
    def load_models(self):
        # –ü–æ–∏—Å–∫ .pt —Ñ–∞–π–ª–æ–≤ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ models
        models_dir = "models"
        if os.path.exists(models_dir):
            model_files = [f for f in os.listdir(models_dir) if f.endswith('.pt')]
            if model_files:
                self.model_combo.addItems([os.path.join(models_dir, f) for f in model_files])
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã .pt –≤ –∫–æ—Ä–Ω–µ–≤–æ–º –∫–∞—Ç–∞–ª–æ–≥–µ, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö —Ç–æ–∂–µ
        root_models = [f for f in os.listdir() if f.endswith('.pt')]
        if root_models:
            self.model_combo.addItems(root_models)
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if self.parent() and hasattr(self.parent(), 'config'):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º get_last_model –≤–º–µ—Å—Ç–æ get_model_settings
            last_model = self.parent().config.get_last_model()
            if last_model:
                index = self.model_combo.findText(last_model)
                if index >= 0:
                    self.model_combo.setCurrentIndex(index)
                else:
                    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ, –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë
                    self.model_combo.addItem(last_model)
                    self.model_combo.setCurrentIndex(self.model_combo.count() - 1)
    
    def load_calibration_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞ calibration_data.json."""
        calibration_file = "calibration_data.json"
        if os.path.exists(calibration_file):
            try:
                with open(calibration_file, "r") as f:
                    self.calibration_data = json.load(f)
                if self.calibration_data:
                    self.is_calibrated = True
                    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ {calibration_file}")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
        else:
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            alt_paths = [
                os.path.join("calibration", "camera_calibration.json"),
                os.path.join("calibration", "calibration_data.json")
            ]
            
            for path in alt_paths:
                if os.path.exists(path):
                    try:
                        with open(path, "r") as f:
                            self.calibration_data = json.load(f)
                        if self.calibration_data:
                            self.is_calibrated = True
                            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ {path}")
                            break
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ {path}: {e}")
            
            if not self.is_calibrated:
                print("–§–∞–π–ª –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    def load_sync_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞ sync_data.json."""
        sync_file = "sync_data.json"
        if os.path.exists(sync_file):
            try:
                with open(sync_file, "r") as f:
                    self.sync_data = json.load(f)
                if self.sync_data and 'time_diff' in self.sync_data:
                    self.is_synced = True
                    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ {sync_file}")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
        else:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ sync
            sync_dir = "sync"
            if os.path.exists(sync_dir):
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                sync_files = [f for f in os.listdir(sync_dir) if f.startswith("sync_") and f.endswith(".json")]
                if sync_files:
                    latest_file = max(sync_files, key=lambda f: os.path.getmtime(os.path.join(sync_dir, f)))
                    
                    try:
                        with open(os.path.join(sync_dir, latest_file), "r") as f:
                            self.sync_data = json.load(f)
                        if self.sync_data and 'time_diff' in self.sync_data:
                            self.is_synced = True
                            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ {os.path.join(sync_dir, latest_file)}")
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
            
            if not self.is_synced:
                print("–§–∞–π–ª —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    def on_calibrate_clicked(self):
        # –í—ã–∑–æ–≤ –¥–∏–∞–ª–æ–≥–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        if self.parent():
            self.parent().open_calibration_dialog()
            
    def on_sync_clicked(self):
        # –í—ã–∑–æ–≤ –¥–∏–∞–ª–æ–≥–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        if self.parent():
            self.parent().open_sync_dialog()
    
    def start_distance_calculation(self):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–Ω—ã –ª–∏ —Ä–∞–∑–Ω—ã–µ –∫–∞–º–µ—Ä—ã
        cam1_name = self.cam1_combo.currentText()
        cam2_name = self.cam2_combo.currentText()
        cam1_url = self.cam1_combo.currentData()
        cam2_url = self.cam2_combo.currentData()
        
        if cam1_name == cam2_name:
            QMessageBox.warning(self, "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –∫–∞–º–µ—Ä—ã –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è")
            return
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å
        model_path = self.model_combo.currentText()
        if not model_path:
            QMessageBox.warning(self, "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å YOLO")
            return
            
        baseline = self.baseline_spin.value()
        
        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        self.calculation_thread = DistanceCalculationThread(
            cam1_url, cam2_url, model_path, baseline, 
            self.calibration_data, self.sync_data
        )
        self.calculation_thread.frame_signal.connect(self.update_display)
        self.calculation_thread.error_signal.connect(self.on_error)
        
        self.calculation_thread.start()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º UI
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.cam1_combo.setEnabled(False)
        self.cam2_combo.setEnabled(False)
        self.model_combo.setEnabled(False)
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è
        self.objects_text.clear()
        self.stats_text.clear()
        self.stats_text.append("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        self.stats_text.append(f"–ö–∞–º–µ—Ä–∞ 1: {cam1_name} ({cam1_url})")
        self.stats_text.append(f"–ö–∞–º–µ—Ä–∞ 2: {cam2_name} ({cam2_url})")
        self.stats_text.append(f"–ú–æ–¥–µ–ª—å: {model_path}")
        self.stats_text.append(f"–ë–∞–∑–∏—Å: {baseline} —Å–º")
        if self.is_calibrated:
            self.stats_text.append("‚úÖ –ö–∞–º–µ—Ä—ã –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω—ã")
        if self.is_synced:
            self.stats_text.append(f"‚úÖ –ö–∞–º–µ—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã (drift_rate: {self.sync_data.get('drift_rate', 0):.2f})")
    
    def stop_distance_calculation(self):
        if self.calculation_thread and self.calculation_thread.isRunning():
            self.calculation_thread.stop()
            
        # –û–±–Ω–æ–≤–ª—è–µ–º UI
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.cam1_combo.setEnabled(True)
        self.cam2_combo.setEnabled(True)
        self.model_combo.setEnabled(True)
        
        # –û—á–∏—â–∞–µ–º –¥–∏—Å–ø–ª–µ–π
        self.video_label.setText("–ù–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ' –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
    
    def update_display(self, original_frame, processed_frame, info):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫—É—é –∫–∞–º–µ—Ä—É –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å
        display_index = self.display_combo.currentIndex()
        frame_to_display = processed_frame if display_index == 0 else original_frame
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–¥—Ä –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        rgb_image = cv2.cvtColor(frame_to_display, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_image.shape
        bytes_per_line = ch * w
        q_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
        self.video_label.setPixmap(QPixmap.fromImage(q_image).scaled(
            self.video_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation))
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö
        self.objects_text.clear()
        detections = info.get('detections', {})
        if detections:
            for obj_id, obj_data in detections.items():
                cls_name = obj_data['class']
                distance = obj_data['distance']
                confidence = obj_data['confidence']
                
                # –†–∞–∑–Ω—ã–π —Ü–≤–µ—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
                if distance < 2:  # –±–ª–∏–∂–µ 2 –º–µ—Ç—Ä–æ–≤
                    color = "red"
                elif distance < 5:  # 2-5 –º–µ—Ç—Ä–æ–≤
                    color = "orange"
                else:
                    color = "green"
                    
                self.objects_text.append(
                    f"<span style='color:{color};'><b>{cls_name}</b>: "
                    f"{distance:.2f} –º (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})</span>"
                )
        else:
            self.objects_text.append("–û–±—ä–µ–∫—Ç—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
    
    def update_statistics(self):
        if self.calculation_thread and self.calculation_thread.isRunning():
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏, 
            # –Ω–∞–ø—Ä–∏–º–µ—Ä FPS, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            pass
    
    def on_error(self, error_msg):
        QMessageBox.critical(self, "–û—à–∏–±–∫–∞", error_msg)
        self.stop_distance_calculation()
    
    def closeEvent(self, event):
        self.stop_distance_calculation()
        event.accept()

    def start_automatic_measurement(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –∏–∑–º–µ—Ä–µ–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
        # –í—ã–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ä—Ç –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø–æ—Å–ª–µ –∫–æ—Ä–æ—Ç–∫–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏, —á—Ç–æ–±—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —É—Å–ø–µ–ª –æ–±–Ω–æ–≤–∏—Ç—å—Å—è
        QTimer.singleShot(500, self.start_distance_calculation) 